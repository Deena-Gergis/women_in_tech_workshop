{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "DATA_PATH = '../data/processed/02_cleaned_df.pkl'\n",
    "MODEL_DIR = '../models'\n",
    "\n",
    "ROLE_COLS  = ['DevType']\n",
    "TECH_COLS  = ['LanguageHaveWorkedWith',\n",
    "              'DatabaseHaveWorkedWith',\n",
    "              'WebframeHaveWorkedWith',\n",
    "              'MiscTechHaveWorkedWith',\n",
    "              'ToolsTechHaveWorkedWith']\n",
    "\n",
    "EXCLUDE_ROLES = ['Other (please specify):',\n",
    "                 'Student',\n",
    "                 'Designer',\n",
    "                 'Educator',\n",
    "                 'Marketing or sales professional',\n",
    "                 'Engineering manager',\n",
    "                 'Senior Executive (C-Suite, VP, etc.)',\n",
    "                 'Product manager',\n",
    "                 'Engineer, site reliability']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "import yaml\n",
    "import time\n",
    "import datetime\n",
    "import copy\n",
    "\n",
    "from scripts.preprocessing import one_hot_encode\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn import linear_model\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import auc, accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.ensemble import StackingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Functions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def calculate_quality(ground_truth, predictions, metric_function, sort_values=False):\n",
    "    quality_scores = {}\n",
    "    for col in predictions.columns:\n",
    "        role_pred = predictions[col].copy()\n",
    "        role_truth = ground_truth[col].copy()\n",
    "        quality_scores[col] = round(metric_function(role_truth, role_pred) * 100, 2)\n",
    "\n",
    "    quality_scores = pd.Series(quality_scores.values(), index=quality_scores.keys())\n",
    "    if sort_values:\n",
    "        quality_scores = quality_scores.sort_values()\n",
    "\n",
    "    return quality_scores"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_train_test_data(job, ohe_tech, ohe_roles):\n",
    "    # Split to train and test\n",
    "    role_mask = (ohe_roles[job] == 1)\n",
    "    role_n = role_mask.sum()\n",
    "\n",
    "    i_role  = role_mask[role_mask].index.tolist()\n",
    "    i_other = role_mask[~role_mask].sample(role_n, random_state=0).index.tolist()\n",
    "\n",
    "    i_role_train,  i_role_test  = train_test_split(i_role,  test_size=0.3, random_state=0)\n",
    "    i_other_train, i_other_test = train_test_split(i_other, test_size=0.3, random_state=0)\n",
    "\n",
    "    i_train = i_role_train + i_other_train\n",
    "    i_test  = i_role_test  + i_other_test\n",
    "\n",
    "    X_train, y_train = ohe_tech.loc[i_train], ohe_roles[job].loc[i_train]\n",
    "    X_test,  y_test  = ohe_tech.loc[i_test], ohe_roles[job].loc[i_test]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load data and preprocess"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Read data\n",
    "processed_df = pd.read_pickle(DATA_PATH)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# One hot encode\n",
    "ohe_df = one_hot_encode(processed_df, ROLE_COLS + TECH_COLS)\n",
    "ohe_df = ohe_df.drop(EXCLUDE_ROLES, axis=1, level=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Split X & Y\n",
    "ohe_tech  = ohe_df[TECH_COLS].droplevel(0, axis=1)\n",
    "ohe_roles = ohe_df[ROLE_COLS].droplevel(0, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Check sums\n",
    "ohe_roles.sum().sort_values()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create template model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rf_clf =  RandomForestClassifier(max_depth=3, n_estimators=5000, random_state=0)\n",
    "\n",
    "en_clf =  Pipeline([('std_scale', StandardScaler()),\n",
    "                    ('cv_elastic_net',\n",
    "                     GridSearchCV(\n",
    "                        linear_model.LogisticRegression(penalty='elasticnet',\n",
    "                                                        solver='saga',\n",
    "                                                        max_iter=1000,\n",
    "                                                        random_state=0),\n",
    "                         param_grid={'C':        np.linspace(0.5, 1.5, 10),\n",
    "                                     'l1_ratio': np.linspace(0,   1,   10)},\n",
    "                         n_jobs=6))\n",
    "                    ])\n",
    "\n",
    "stacked_clf = StackingClassifier(estimators=[('random_forest', rf_clf),\n",
    "                                             ('elastic_net',   en_clf)],\n",
    "                                 final_estimator=linear_model.LogisticRegression())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = {}\n",
    "models = {}\n",
    "unique_jobs = ohe_roles.columns.to_list()\n",
    "\n",
    "for job in unique_jobs:\n",
    "     print(str(datetime.datetime.now()) + ' ... Training model for ' + job)\n",
    "\n",
    "     # Create and save data\n",
    "     X_train, X_test, y_train, y_test = get_train_test_data(job, ohe_tech, ohe_roles)\n",
    "     data[job] = {'X_train': X_train, 'X_test': X_test, 'y_train': y_train, 'y_test': y_test}\n",
    "\n",
    "     # Fit and save model\n",
    "     job_model = copy.deepcopy(stacked_clf)\n",
    "     job_model.fit(X_train, y_train)\n",
    "     models[job] = copy.deepcopy(job_model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluate models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_evaluation = {}\n",
    "test_evaluation  = {}\n",
    "\n",
    "for job in unique_jobs:\n",
    "    print(str(datetime.datetime.now()) + ' ... Evaluating ' + job)\n",
    "\n",
    "    model = models[job]\n",
    "    train_fit = classification_report(data[job]['y_train'], model.predict(data[job]['X_train']), output_dict=True)\n",
    "    train_evaluation[job] = train_fit['weighted avg']\n",
    "\n",
    "    test_fit = classification_report(data[job]['y_test'], model.predict(data[job]['X_test']), output_dict=True)\n",
    "    test_evaluation[job] = test_fit['weighted avg']\n",
    "\n",
    "test_evaluation  = pd.DataFrame(test_evaluation).T\n",
    "train_evaluation = pd.DataFrame(train_evaluation).T"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_evaluation.T"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_evaluation.T"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Calculate feature importances"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "models = pickle.load(open('../models/ensemble_models.pkl', 'rb'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "features_imps = {}\n",
    "\n",
    "for job in unique_jobs:\n",
    "    print(str(datetime.datetime.now()) + ' ... Calculating feature importances ' + job)\n",
    "\n",
    "    features_importances = permutation_importance(models[job],\n",
    "                                                  data[job]['X_train'],\n",
    "                                                  data[job]['y_train'],\n",
    "                                                  n_repeats=12,\n",
    "                                                  random_state=0,\n",
    "                                                  n_jobs=6)\n",
    "    features_importances.pop('importances')\n",
    "    features_importances = pd.DataFrame.from_dict(features_importances)\n",
    "    features_importances.index = X_train.columns\n",
    "\n",
    "    features_imps[job] = features_importances.sort_values('importances_mean', ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "[print(job, imp[:10].index.tolist()) for job, imp in features_imps.items()]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Exporting"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open(os.path.join(MODEL_DIR, 'ensemble_models.pkl'), 'wb') as handle:\n",
    "    pickle.dump(models, handle)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open(os.path.join(MODEL_DIR, 'ensemble_models_eval.pkl'), 'wb') as handle:\n",
    "    pickle.dump({'train': train_evaluation, 'test': test_evaluation}, handle)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open(os.path.join(MODEL_DIR, 'ensemble_models_feature_importances.pkl'), 'wb') as handle:\n",
    "    pickle.dump(features_imps, handle)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}